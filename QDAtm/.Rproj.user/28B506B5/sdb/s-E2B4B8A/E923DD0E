{
    "contents" : "# Example from JSM article by Ingo Feinerer\n\n###################################################\n### chunk number 1: Preliminaries\n###################################################\nlibrary(\"clue\")\nlibrary(\"tm\")\n\n\n###################################################\n### chunk number 2: NewCorpus eval=FALSE\n###################################################\n## new(\"Corpus\", .Data = ..., DMetaData = ..., CMetaData = ..., DBControl = ...)\n\n\n###################################################\n### chunk number 3: CorpusConstructor eval=FALSE\n###################################################\n## Corpus(object = ...,\n##            readerControl = list(reader = object@DefaultReader,\n##                            language = \"en_US\",\n##                            load = FALSE),\n##            dbControl = list(useDb = TRUE,\n##                             dbName = \"texts.db\",\n##                             dbType = \"DB1\"))\n\n\n###################################################\n### chunk number 4: NewPlainTextDocument eval=FALSE\n###################################################\n## new(\"PlainTextDocument\", .Data = \"Some text.\", URI = uri, Cached = TRUE,\n##     Author = \"Mr. Nobody\", DateTimeStamp = Sys.time(),\n##     Description = \"Example\", ID = \"ID1\", Origin = \"Custom\",\n##     Heading = \"Ex. 1\", Language = \"en_US\")\n\n\n###################################################\n### chunk number 5: NewTextRepository eval=FALSE\n###################################################\n## new(\"TextRepository\",\n##     .Data = list(Col1, Col2), RepoMetaData = list(created = \"now\"))\n\n\n###################################################\n### chunk number 6: NewTermDocMatrix eval=FALSE\n###################################################\n## new(\"TermDocMatrix\", Data = tdm, Weighting = weightTf)\n\n\n###################################################\n### chunk number 7: WekaTokenizer eval=FALSE\n###################################################\n## TermDocMatrix(col, control = list(tokenize = NGramTokenizer))\n\n\n###################################################\n### chunk number 8: openNLPTokenizer eval=FALSE\n###################################################\n## TermDocMatrix(col, control = list(tokenize = tokenize))\n\n\n###################################################\n### chunk number 9: SentenceDetection eval=FALSE\n###################################################\n## TermDocMatrix(col, control = list(tokenize = sentDetect))\n\n\n###################################################\n### chunk number 10: NewDirSource eval=FALSE\n###################################################\n## new(\"DirSource\", LoDSupport = TRUE, FileList = dir(),\n##     Position = 0, DefaultReader = readPlain, Encoding = \"latin1\")\n\n\n###################################################\n### chunk number 11: Ovid\n###################################################\ntxt <- system.file(\"texts\", \"txt\", package = \"tm\")\n(ovid <- Corpus(DirSource(txt),\n                readerControl = list(reader = readPlain,\n                                     language = \"la\",\n                                     load = TRUE)))\n\n\n###################################################\n### chunk number 12: CorpusDBSupport eval=FALSE\n###################################################\n## Corpus(DirSource(txt),\n##            readerControl = list(reader = readPlain,\n##                                 language = \"la\", load = TRUE),\n##            dbControl = list(useDb = TRUE,\n##                             dbName = \"/home/user/oviddb\",\n##                             dbType = \"DB1\"))\n\n\n###################################################\n### chunk number 13: IDOvid\n###################################################\nID(ovid[[1]])\n\n\n###################################################\n### chunk number 14: AuthorOvid\n###################################################\nAuthor(ovid[[1]]) <- \"Publius Ovidius Naso\"\n\n\n###################################################\n### chunk number 15: \n###################################################\nmeta(ovid[[1]])\n\n\n###################################################\n### chunk number 16: OvidSubset\n###################################################\novid[1:3]\n\n\n###################################################\n### chunk number 17: OvidDocument\n###################################################\novid[[1]]\n\n\n###################################################\n### chunk number 18: Concatenation\n###################################################\nc(ovid[1:2], ovid[3:4])\n\n\n###################################################\n### chunk number 19: LengthOvid\n###################################################\nlength(ovid)\n\n\n###################################################\n### chunk number 20: SummaryOvid\n###################################################\nsummary(ovid)\n\n\n###################################################\n### chunk number 21: tmUpdate\n###################################################\ntmUpdate(ovid, DirSource(txt))\n\n\n###################################################\n### chunk number 22: OvidMeta\n###################################################\novid <- appendMeta(ovid,\n                   cmeta = list(test = c(1,2,3)),\n                   dmeta = list(clust = c(1,1,2,2,2)))\nsummary(ovid)\nCMetaData(ovid)\nDMetaData(ovid)\n\n\n###################################################\n### chunk number 23: OvidAppendElem\n###################################################\n(ovid <- appendElem(ovid, data = ovid[[1]], list(clust = 1)))\n\n\n###################################################\n### chunk number 24: TextRepo\n###################################################\n(repo <- TextRepository(ovid))\n\n\n###################################################\n### chunk number 25: TextRepoMeta\n###################################################\nrepo <- appendElem(repo, ovid, list(modified = date()))\nrepo <- appendMeta(repo, list(moremeta = 5:10))\nsummary(repo)\nRepoMetaData(repo)\n\n\n###################################################\n### chunk number 26: \n###################################################\nmeta(ovid, type = \"corpus\", \"foo\") <- \"bar\"\nmeta(ovid, type = \"corpus\")\nmeta(ovid, \"someTag\") <- 6:11\nmeta(ovid)\n\n\n###################################################\n### chunk number 27: tmMap\n###################################################\ntmMap(ovid, FUN = tmTolower)\n\n\n###################################################\n### chunk number 28: tmFilter\n###################################################\ntmFilter(ovid, FUN = searchFullText, \"Venus\", doclevel = TRUE)\n\n\n###################################################\n### chunk number 29: tmIndex\n###################################################\ntmIndex(ovid, \"identifier == '2'\")\n\n\n###################################################\n### chunk number 30: GmaneSource eval=FALSE\n###################################################\n## setClass(\"GmaneSource\",\n##          representation(URI = \"ANY\", Content = \"list\"),\n##          contains = c(\"Source\"))\n\n\n###################################################\n### chunk number 31: GmaneSourceConstructor eval=FALSE\n###################################################\n## setMethod(\"GmaneSource\",\n##           signature(object = \"ANY\"),\n##           function(object, encoding = \"UTF-8\") {\n##               ## ---code chunk---\n##               new(\"GmaneSource\", LoDSupport = FALSE, URI = object,\n##                   Content = content, Position = 0, Encoding = encoding)\n##           })\n\n\n###################################################\n### chunk number 32: stepNext eval=FALSE\n###################################################\n## setMethod(\"stepNext\",\n##           signature(object = \"GmaneSource\"),\n##           function(object) {\n##               object@Position <- object@Position + 1\n##               object\n##           })\n\n\n###################################################\n### chunk number 33: getElem eval=FALSE\n###################################################\n## setMethod(\"getElem\",\n##           signature(object = \"GmaneSource\"),\n##           function(object) {\n##               ## ---code chunk---\n##               list(content = content, uri = object@URI)\n##           })\n\n\n###################################################\n### chunk number 34: eoi eval=FALSE\n###################################################\n## setMethod(\"eoi\",\n##           signature(object = \"GmaneSource\"),\n##           function(object) {\n##               length(object@Content) <= object@Position\n##           })\n\n\n###################################################\n### chunk number 35: readGmane eval=FALSE\n###################################################\n## readGmane <- FunctionGenerator(function(...) {\n##     function(elem, load, language, id) {\n##         ## ---code chunk---\n##         new(\"NewsgroupDocument\", .Data = content, URI = elem$uri,\n##             Cached = TRUE, Author = author, DateTimeStamp = datetimestamp,\n##             Description = \"\", ID = id, Origin = origin, Heading = heading,\n##             Language = language, Newsgroup = newsgroup)\n##     }\n## })\n\n\n###################################################\n### chunk number 36: GmaneCorpus\n###################################################\nrss <- system.file(\"texts\", \"gmane.comp.lang.r.gr.rdf\", package = \"tm\")\nCorpus(GmaneSource(rss), readerControl = list(reader = readGmane, language = \"en_US\", load = TRUE))\n\n\n###################################################\n### chunk number 37: readPDF eval=FALSE\n###################################################\n## readPDF <- FunctionGenerator(function(...) {\n##   function(elem, load, language, id) {\n##     ## get metadata\n##     meta <- system(paste(\"pdfinfo\", as.character(elem$uri[2])),\n##                    intern = TRUE)\n## \n##     ## extract and store main information, e.g.:\n##     heading <- gsub(\"Title:[[:space:]]*\", \"\",\n##                     grep(\"Title:\", meta, value = TRUE))\n## \n##     ## [... similar for other metadata ...]\n## \n##     ## extract text from PDF using the external pdftotext utility:\n##     corpus <- paste(system(paste(\"pdftotext\", as.character(elem$uri[2]), \"-\"),\n##                            intern = TRUE),\n##                     sep = \"\\n\", collapse = \"\")\n## \n##     ## create new text document object:\n##     new(\"PlainTextDocument\", .Data = corpus, URI = elem$uri, Cached = TRUE,\n##         Author = author, DateTimeStamp = datetimestamp,\n##         Description = description, ID = id, Origin = origin,\n##         Heading = heading, Language = language)\n##     }\n## })\n\n\n###################################################\n### chunk number 38: TransformExtension eval=FALSE\n###################################################\n## setGeneric(\"myTransform\", function(object, ...) standardGeneric(\"myTransform\"))\n## setMethod(\"myTransform\",\n##           signature(object = \"PlainTextDocument\"),\n##           function(object, ..., DMetaData) {\n##               Content(object) <- doSomeThing(object, DMetaData)\n##               return(object)\n##           })\n\n\n###################################################\n### chunk number 39: Reuters\n###################################################\nreut21578XMLgz <- system.file(\"texts\", \"reut21578.xml.gz\", package = \"tm\")\n(Reuters <- Corpus(ReutersSource(gzfile(reut21578XMLgz)),\n                   readerControl = list(reader = readReut21578XML,\n                                        language = \"en_US\",\n                                        load = TRUE)))\n\n\n###################################################\n### chunk number 40: \n###################################################\ntmMap(Reuters, asPlain)\n\n\n###################################################\n### chunk number 41:  eval=FALSE\n###################################################\n## tmFilter(crude, \"Topics == 'crude'\")\n\n\n###################################################\n### chunk number 42: AcqCrude\n###################################################\ndata(\"acq\")\ndata(\"crude\")\n\n\n###################################################\n### chunk number 43:  eval=FALSE\n###################################################\n## acq[[10]]\n\n\n###################################################\n### chunk number 44: \n###################################################\nstrwrap(acq[[10]])\n\n\n###################################################\n### chunk number 45:  eval=FALSE\n###################################################\n## stemDoc(acq[[10]])\n\n\n###################################################\n### chunk number 46: \n###################################################\nstrwrap(stemDoc(acq[[10]]))\n\n\n###################################################\n### chunk number 47: \n###################################################\ntmMap(acq, stemDoc)\n\n\n###################################################\n### chunk number 48:  eval=FALSE\n###################################################\n## stripWhitespace(acq[[10]])\n\n\n###################################################\n### chunk number 49: \n###################################################\nstrwrap(stripWhitespace(acq[[10]]))\n\n\n###################################################\n### chunk number 50:  eval=FALSE\n###################################################\n## tmTolower(acq[[10]])\n\n\n###################################################\n### chunk number 51: \n###################################################\nstrwrap(tmTolower(acq[[10]]))\n\n\n###################################################\n### chunk number 52: stopwords\n###################################################\nmystopwords <- c(\"and\", \"for\", \"in\", \"is\", \"it\", \"not\", \"the\", \"to\")\n\n\n###################################################\n### chunk number 53:  eval=FALSE\n###################################################\n## removeWords(acq[[10]], mystopwords)\n\n\n###################################################\n### chunk number 54: \n###################################################\nstrwrap(removeWords(acq[[10]], mystopwords))\n\n\n###################################################\n### chunk number 55:  eval=FALSE\n###################################################\n## tmMap(acq, removeWords, mystopwords)\n\n\n###################################################\n### chunk number 56:  eval=FALSE\n###################################################\n## stopwords(language = ...)\n\n\n###################################################\n### chunk number 57: \n###################################################\nlibrary(\"wordnet\")\n\n\n###################################################\n### chunk number 58: \n###################################################\nsynonyms(\"company\")\n\n\n###################################################\n### chunk number 59:  eval=FALSE\n###################################################\n## replaceWords(acq[[10]], synonyms(dict, \"company\"), by = \"company\")\n\n\n###################################################\n### chunk number 60:  eval=FALSE\n###################################################\n## tmMap(acq, replaceWords, synonyms(dict, \"company\"), by = \"company\")\n\n\n###################################################\n### chunk number 61:  eval=FALSE\n###################################################\n## library(\"openNLP\")\n## tagPOS(acq[[10]])\n\n\n###################################################\n### chunk number 62: \n###################################################\nlibrary(\"openNLP\")\nstrwrap(tagPOS(acq[[10]]))\n\n\n###################################################\n### chunk number 63: \n###################################################\n# Creates the term-document matrix for our crude data set\ncrudeTDM <- TermDocMatrix(crude, control = list(stopwords = TRUE))\n\n\n###################################################\n### chunk number 64: \n###################################################\n# Terms with more than 10 occurrences\n(crudeTDMHighFreq <- findFreqTerms(crudeTDM, 10, Inf))\n\n\n###################################################\n### chunk number 65: \n###################################################\n# Frequencies for high frequency terms\nData(crudeTDM)[1:10,crudeTDMHighFreq]\n\n\n###################################################\n### chunk number 66: \n###################################################\nfindAssocs(crudeTDM, \"oil\", 0.85)\n\n\n###################################################\n### chunk number 67: \n###################################################\nplot(crudeTDM, corThreshold = 0.5, terms = findFreqTerms(crudeTDM, 6, Inf))\n\n\n###################################################\n### chunk number 68: \n###################################################\nws <- c(acq, crude)\nsummary(ws)\n\n\n###################################################\n### chunk number 69: dissimilarityTermDocMatrix eval=FALSE\n###################################################\n## dissimilarity(crudeTDM, method = \"cosine\")\n\n\n###################################################\n### chunk number 70: dissimilarityTwoDocs\n###################################################\ndissimilarity(crude[[1]], crude[[2]], \"cosine\")\n\n\n###################################################\n### chunk number 71: wsTermDocMatrix\n###################################################\nwsTDM <- Data(TermDocMatrix(ws))\n\n\n###################################################\n### chunk number 72: \n###################################################\nwsHClust <- hclust(dist(wsTDM), method = \"ward\")\n\n\n###################################################\n### chunk number 73: \n###################################################\nplot(wsHClust, labels = c(rep(\"acq\",50), rep(\"crude\",20)))\n\n\n###################################################\n### chunk number 74: kmeans\n###################################################\nwsKMeans <- kmeans(wsTDM, 2)\n\n\n###################################################\n### chunk number 75: \n###################################################\nwsReutersCluster <- c(rep(\"acq\",50), rep(\"crude\",20))\n\n\n###################################################\n### chunk number 76: \n###################################################\ncl_agreement(wsKMeans, as.cl_partition(wsReutersCluster), \"diag\")\n\n\n###################################################\n### chunk number 77: \n###################################################\nlibrary(\"class\")\nlibrary(\"kernlab\")\ndata(spam)\n\n\n###################################################\n### chunk number 78: \n###################################################\ntrain <- rbind(spam[1:1360, ], spam[1814:3905, ])\n\n\n###################################################\n### chunk number 79: \n###################################################\ntrainCl <- train[,\"type\"]\n\n\n###################################################\n### chunk number 80: \n###################################################\ntest <- rbind(spam[1361:1813, ], spam[3906:4601, ])\n\n\n###################################################\n### chunk number 81: \n###################################################\ntrueCl <- test[,\"type\"]\n\n\n###################################################\n### chunk number 82: knn\n###################################################\nknnCl <- knn(train[,-58], test[,-58], trainCl)\n\n\n###################################################\n### chunk number 83: \n###################################################\n(nnTable <- table(\"1-NN\" = knnCl, \"Reuters\" = trueCl))\n\n\n###################################################\n### chunk number 84: \n###################################################\nsum(diag(nnTable))/nrow(test)\n\n\n###################################################\n### chunk number 85: ksvm\n###################################################\nksvmTrain <- ksvm(type ~ ., data = train)\n\n\n###################################################\n### chunk number 86: \n###################################################\nsvmCl <- predict(ksvmTrain, test[,-58])\n\n\n###################################################\n### chunk number 87: \n###################################################\n(svmTable <- table(\"SVM\" = svmCl, \"Reuters\" = trueCl))\n\n\n###################################################\n### chunk number 88: \n###################################################\nsum(diag(svmTable))/nrow(test)\n\n\n###################################################\n### chunk number 89: \n###################################################\n# Instantiate both string kernels\nstringkern <- stringdot(type = \"string\")\n\n\n###################################################\n### chunk number 90:  eval=FALSE\n###################################################\n## # Perform spectral clustering with string kernels\n## stringCl <- specc(ws, 2, kernel = stringkern)\n\n\n###################################################\n### chunk number 91: specc\n###################################################\nset.seed(1234)\nstringkern\nstringCl <- as.vector(specc(ws, 2, kernel = stringkern))\n\n\n###################################################\n### chunk number 92: \n###################################################\ntable(\"String Kernel\" = stringCl, \"Reuters\" = wsReutersCluster)\n\n\n###################################################\n### chunk number 93:  eval=FALSE\n###################################################\n## convertMboxEml(\"2006.txt\", \"2006/\")\n\n\n###################################################\n### chunk number 94: Rdevel eval=FALSE\n###################################################\n## rdevel <- Corpus(DirSource(\"2006/\"),\n##                      readerControl = list(reader = readNewsgroup,\n##                                           language = \"en_US\",\n##                                           load = TRUE))\n\n\n###################################################\n### chunk number 95:  eval=FALSE\n###################################################\n## rdevel <- tmMap(rdevel, asPlain)\n\n\n###################################################\n### chunk number 96:  eval=FALSE\n###################################################\n## rdevel <- tmMap(rdevel, stripWhitespace)\n## rdevel <- tmMap(rdevel, tmTolower)\n\n\n###################################################\n### chunk number 97:  eval=FALSE\n###################################################\n## summary(rdevel)\n\n\n###################################################\n### chunk number 98:  eval=FALSE\n###################################################\n## tdm <- TermDocMatrix(rdevel, list(stemming = TRUE, stopwords = TRUE))\n\n\n###################################################\n### chunk number 99:  eval=FALSE\n###################################################\n## authors <- lapply(rdevel, Author)\n## authors <- sapply(authors, paste, collapse = \" \")\n\n\n###################################################\n### chunk number 100:  eval=FALSE\n###################################################\n## sort(table(authors), decreasing = TRUE)[1:3]\n\n\n###################################################\n### chunk number 101:  eval=FALSE\n###################################################\n## headings <- lapply(rdevel, Heading)\n## headings <- sapply(headings, paste, collapse = \" \")\n\n\n###################################################\n### chunk number 102:  eval=FALSE\n###################################################\n## (bigTopicsTable <- sort(table(headings), decreasing = TRUE)[1:3])\n## bigTopics <- names(bigTopicsTable)\n\n\n###################################################\n### chunk number 103:  eval=FALSE\n###################################################\n## topicCol <- rdevel[headings == bigTopics[1]]\n## unique(sapply(topicCol, Author))\n\n\n###################################################\n### chunk number 104:  eval=FALSE\n###################################################\n## topicCol <- rdevel[headings == bigTopics[2]]\n## unique(sapply(topicCol, Author))\n\n\n###################################################\n### chunk number 105: bugCol eval=FALSE\n###################################################\n## (bugCol <- tmFilter(rdevel,\n##                     FUN = searchFullText, \"[^[:alpha:]]+bug[^[:alpha:]]+\",\n##                     doclevel = TRUE))\n\n\n###################################################\n### chunk number 106:  eval=FALSE\n###################################################\n## bugColAuthors <- lapply(bugCol, Author)\n## bugColAuthors <- sapply(bugColAuthors, paste, collapse = \" \")\n## sort(table(bugColAuthors), decreasing = TRUE)[1:3]\n\n\n###################################################\n### chunk number 107: findFreqTermsTDM eval=FALSE\n###################################################\n## f <- findFreqTerms(tdm, 30, 31)\n## sort(f[-grep(\"[0-9]\", f)])\n\n\n###################################################\n### chunk number 108: removeCitationSignature\n###################################################\nsetGeneric(\"removeCitationSignature\",\n           function(object, ...) standardGeneric(\"removeCitationSignature\"))\nsetMethod(\"removeCitationSignature\",\n          signature(object = \"PlainTextDocument\"),\n          function(object, ...) {\n            c <- Content(object)\n            \n            ## Remove citations starting with '>'\n            citations <- grep(\"^[[:blank:]]*>.*\", c)\n            if (length(citations) > 0)\n              c <- c[-citations]\n            \n            ## Remove signatures starting with '-- '\n            signatureStart <- grep(\"^-- $\", c)\n            if (length(signatureStart) > 0)\n              c <- c[-(signatureStart:length(c))]\n            \n            Content(object) <- c\n            return(object)\n          })\n\n\n###################################################\n### chunk number 109:  eval=FALSE\n###################################################\n## rdevelInc <- tmMap(rdevel, removeCitationSignature)\n\n\n###################################################\n### chunk number 110:  eval=FALSE\n###################################################\n## tdmInc <- TermDocMatrix(rdevelInc, list(stemming = TRUE, stopwords = TRUE))\n\n\n###################################################\n### chunk number 111: findFreqTermsTDMInc eval=FALSE\n###################################################\n## f <- findFreqTerms(tdmInc, 30, 31)\n## sort(f[-grep(\"[0-9]\", f)])\n\n\n###################################################\n### chunk number 112: subjectCounts eval=FALSE\n###################################################\n## subjectCounts <- 0\n## for (r in rdevelInc) {\n##     ## Get single characters from subject\n##     h <- unlist(strsplit(Heading(r), \" \"))\n## \n##     ## Count unique matches of subject strings within document\n##     len <- length(unique(unlist(lapply(h, grep, r, fixed = TRUE))))\n## \n##     ## Update counter\n##     subjectCounts <- c(subjectCounts, len)\n## }\n## summary(subjectCounts)\n",
    "created" : 1352170367367.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1575529562",
    "id" : "E923DD0E",
    "lastKnownWriteTime" : 1352170810,
    "path" : "~/RStuff/qda_tm/QDAtm/ingo.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}